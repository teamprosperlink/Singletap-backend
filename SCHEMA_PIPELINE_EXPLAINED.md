# ğŸ”„ Schema Pipeline - Complete Flow Explanation

## ğŸ“Š **The Full Architecture**

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: LLM EXTRACTION (GPT-4o API)                â”‚
â”‚ Output: NEW Schema (14 fields, axis-based)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    NEW Schema Format:
    {
      "intent": "product",
      "subintent": "buy",
      "domain": ["technology & electronics"],
      "primary_mutual_category": [],
      "items": [{
        "type": "laptop",
        "categorical": {"brand": "apple", "condition": "used"},
        "min": {
          "capacity": [{"type": "memory", "value": 16, "unit": "gb"}]
        },
        "max": {
          "cost": [{"type": "price", "value": 80000, "unit": "inr"}]
        },
        "range": {}
      }],
      "item_exclusions": [],
      "other_party_preferences": {
        "identity": [{"type": "language", "value": "kannada"}],
        "habits": {},
        "min": {},
        "max": {},
        "range": {}
      },
      "other_party_exclusions": {},
      "self_attributes": {
        "identity": [],
        "habits": {},
        "min": {},
        "max": {},
        "range": {}
      },
      "self_exclusions": {},
      "target_location": {"name": "bangalore"},
      "location_match_mode": "explicit",
      "location_exclusions": [],
      "reasoning": "..."
    }
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2.1: SCHEMA NORMALIZER V2                     â”‚
â”‚ File: schema_normalizer_v2.py                       â”‚
â”‚ Function: normalize_and_validate_v2()                â”‚
â”‚                                                      â”‚
â”‚ Transforms:                                          â”‚
â”‚ - NEW schema (14 fields) â†’ OLD schema (12 fields)   â”‚
â”‚ - Axis-based constraints â†’ Flat constraints         â”‚
â”‚ - Field renames (12 mappings)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    OLD Schema Format:
    {
      "intent": "product",
      "subintent": "buy",
      "domain": ["technology & electronics"],
      "category": [],  // â† renamed from primary_mutual_category
      "items": [{
        "type": "laptop",
        "categorical": {"brand": "apple", "condition": "used"},
        "min": {"memory": 16},  // â† flattened from axis-based
        "max": {"price": 80000},  // â† flattened from axis-based
        "range": {}
      }],
      "itemexclusions": [],  // â† renamed from item_exclusions
      "other": {  // â† renamed from other_party_preferences
        "categorical": {"language": "kannada"},  // â† flattened from identity axis
        "min": {},
        "max": {},
        "range": {},
        "otherexclusions": []  // â† nested inside
      },
      "self": {  // â† renamed from self_attributes
        "categorical": {},
        "min": {},
        "max": {},
        "range": {},
        "selfexclusions": []  // â† nested inside
      },
      "location": "bangalore",  // â† simplified from target_location
      "locationmode": "explicit",  // â† renamed from location_match_mode
      "locationexclusions": [],
      "reasoning": "..."
    }
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2.4-2.7: MATCHING ENGINE                      â”‚
â”‚ Files:                                               â”‚
â”‚ - listing_matcher_v2.py (orchestration)             â”‚
â”‚ - item_array_matchers.py (item matching)            â”‚
â”‚ - other_self_matchers.py (other/self matching)      â”‚
â”‚ - location_matcher_v2.py (location matching)        â”‚
â”‚                                                      â”‚
â”‚ Expects: OLD schema format                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    Match Result: True/False
```

---

## ğŸ”‘ **Key Transformations in schema_normalizer_v2.py**

### **1. Field Name Mappings (12 renames)**

| NEW Field Name | OLD Field Name | Notes |
|----------------|----------------|-------|
| `intent` | `intent` | No change |
| `subintent` | `subintent` | No change |
| `domain` | `domain` | No change |
| `items` | `items` | No change (but contents transformed) |
| `reasoning` | `reasoning` | No change |
| `primary_mutual_category` | `category` | âœ… Renamed |
| `item_exclusions` | `itemexclusions` | âœ… Renamed |
| `other_party_preferences` | `other` | âœ… Renamed |
| `other_party_exclusions` | `other.otherexclusions` | âœ… Nested inside |
| `self_attributes` | `self` | âœ… Renamed |
| `self_exclusions` | `self.selfexclusions` | âœ… Nested inside |
| `target_location` | `location` | âœ… Renamed + simplified |
| `location_match_mode` | `locationmode` | âœ… Renamed |
| `location_exclusions` | `locationexclusions` | No change |

---

### **2. Axis-Based â†’ Flat Constraint Transformation**

#### **For Items:**

**NEW (axis-based):**
```json
"min": {
  "capacity": [
    {"type": "memory", "value": 16, "unit": "gb"},
    {"type": "storage", "value": 256, "unit": "gb"}
  ]
}
```

**OLD (flat):**
```json
"min": {
  "memory": 16,
  "storage": 256
}
```

#### **For People (other/self):**

**NEW (axis-based with identity/habits):**
```json
"other_party_preferences": {
  "identity": [
    {"type": "language", "value": "kannada"},
    {"type": "profession", "value": "plumber"}
  ],
  "habits": {
    "smoking": "no",
    "drinking": "no"
  },
  "min": {
    "time": [{"type": "experience", "value": 60, "unit": "months"}]
  }
}
```

**OLD (flat categorical):**
```json
"other": {
  "categorical": {
    "language": "kannada",
    "profession": "plumber",
    "smoking": "no",
    "drinking": "no"
  },
  "min": {
    "experience": 60
  },
  "max": {},
  "range": {}
}
```

---

### **3. Location Simplification**

**NEW:**
```json
"target_location": {"name": "bangalore"},
"location_match_mode": "explicit"
```

**OLD:**
```json
"location": "bangalore",  // Simple string
"locationmode": "explicit"
```

For route mode:
```json
// NEW
"target_location": {"origin": "delhi", "destination": "mumbai"}

// OLD
"location": {"origin": "delhi", "destination": "mumbai"}  // Dict for route
```

---

## âœ… **Your Questions Answered**

### **Q1: Is the API doing its work correctly?**

**YES! âœ…** The API outputs **NEW schema format** correctly:
- 14 fields present âœ…
- Axis-based constraints âœ…
- Proper structure âœ…

The test examples were using **OLD format**, which caused false failures.

---

### **Q2: Does the matching engine schema match API output?**

**NO - But that's by design! âœ…**

- **API outputs:** NEW schema (14 fields, axis-based)
- **Matching engine expects:** OLD schema (12 fields, flat)
- **Solution:** `schema_normalizer_v2.py` transforms between them

**This is the correct architecture!**

---

### **Q3: If schema mismatch, no matches?**

**Correct! But transformation layer prevents this:**

```
API (NEW) â†’ Normalizer â†’ OLD â†’ Matching âœ…
```

Without normalizer:
```
API (NEW) â†’ Matching (expects OLD) â†’ âŒ FAIL
```

---

## ğŸ”§ **Pre-processing: Rule-Based vs API Call?**

### **Current Architecture (Rule-Based Transformation):**

```python
# schema_normalizer_v2.py
def normalize_and_validate_v2(listing: Dict) -> Dict:
    # 1. Validate NEW schema
    validate_new_schema(listing)

    # 2. Transform NEW â†’ OLD (deterministic rules)
    old_listing = transform_new_to_old(listing)

    # 3. Return OLD format
    return old_listing
```

**This is rule-based transformation âœ…**
- Fast (milliseconds)
- Deterministic (100% consistent)
- No API cost
- Already implemented!

---

### **Alternative: Another API Call (NOT NEEDED)**

```
Query â†’ API 1 (extract) â†’ NEW â†’ API 2 (validate/transform) â†’ OLD â†’ Matching
```

**Why this is NOT needed:**
- âŒ 2x cost
- âŒ 2x latency
- âŒ More failure points
- âœ… Rule-based transformation already works!

---

## ğŸ¯ **What You Actually Need**

### **1. API Output Post-Processing (For Edge Cases)**

After API but before normalizer:

```python
def post_process_api_output(api_output: Dict) -> Dict:
    """
    Fix edge cases before normalization:
    - Currency: "local" â†’ "inr"
    - Domain case: "technology & electronics" â†’ "Technology & Electronics"
    - Missing constraints: Add exact values as ranges
    """
    # Use /data/synonyms.json, /pos/data/currencies.json
    return cleaned_output
```

### **2. The Complete Pipeline**

```
Query
    â†“
GPT-4o API (extraction)
    â†“
API Output (NEW schema, might have edge cases)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST-PROCESSOR (NEW)        â”‚
â”‚ - Canonicalize domains      â”‚
â”‚ - Fix currency units        â”‚
â”‚ - Add missing constraints   â”‚
â”‚ - Validate schema           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Cleaned NEW schema
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCHEMA NORMALIZER V2        â”‚
â”‚ (EXISTING - Works!)         â”‚
â”‚ - Transform NEW â†’ OLD       â”‚
â”‚ - Flatten axes              â”‚
â”‚ - Rename fields             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
OLD schema
    â†“
MATCHING ENGINE V2
```

---

## ğŸ“ **Recommendations**

### **What You Have (Already Working):**

1. âœ… API extraction (NEW schema)
2. âœ… schema_normalizer_v2.py (NEW â†’ OLD transformation)
3. âœ… Matching engine V2 (expects OLD schema)

**This pipeline is CORRECT and WORKING!**

---

### **What You Need to Add:**

1. **Post-processor (before normalizer):**
   ```python
   # new file: api_post_processor.py
   def post_process(api_output):
       # Fix currency: local â†’ inr
       # Fix domain case
       # Add missing exact constraints
       # Canonicalize using /data/synonyms.json
       return cleaned_output
   ```

2. **Update test examples:**
   - Change from OLD format to NEW format
   - Or keep OLD and test after normalization

---

### **Do NOT Need:**

- âŒ Another API call for transformation
- âŒ Change matching engine (it's correct)
- âŒ Change schema_normalizer_v2.py (it's correct)

---

## ğŸ¯ **Final Answer to Your Question**

**"Pre-process: Rule-based or API call?"**

**Answer: Rule-based âœ… (Already implemented!)**

- `schema_normalizer_v2.py` IS your rule-based preprocessor
- It transforms NEW â†’ OLD deterministically
- No API call needed for this transformation
- Just add light post-processing for edge cases (currency, domain case)

**Your architecture is already correct!**

---

## ğŸ“Š **Summary**

| Component | Format | Status |
|-----------|--------|--------|
| **API Output** | NEW schema (14 fields) | âœ… Working correctly |
| **schema_normalizer_v2.py** | NEW â†’ OLD transform | âœ… Already implemented |
| **Matching Engine** | OLD schema (12 fields) | âœ… Working correctly |
| **Post-processor (NEW)** | Edge case fixes | ğŸ”§ Need to add |

**Bottom Line:** Your verification script was wrong, not the API. The architecture is correct. Just add edge case post-processing and you're done!
