# ğŸ¯ Quick Answers to Your Questions

## Q1: Schema - NEW vs OLD?

**Answer: There's only ONE schema (the current one).**

### The Schema Uses:

**For Items:**
```json
"items": [{
  "type": "laptop",
  "categorical": {"brand": "apple", "condition": "used"}  // Flat
}]
```

**For People:**
```json
"other_party_preferences": {
  "identity": [{"type": "language", "value": "kannada"}],  // Axis-based
  "habits": {"smoking": "no"}                              // Flat for flags
}
```

This IS the current format from PROMPT_STAGE2.txt.

The "NEW schema" confusion was because test examples used an older/incorrect format.

---

## Q2: Can preprocessing handle schema differences?

**Answer: Yes, both preprocessing AND post-processing can handle it.**

### Options:

**Option A: Preprocessing (Before API)**
```python
# Modify prompt to force specific format
# Not recommended - LLM knows best structure
```

**Option B: Post-processing (After API)** âœ… RECOMMENDED
```python
def normalize_schema(api_output):
    # Validate all 14 fields present
    # Canonicalize values
    # Normalize case/units
    return normalized_output
```

**Why post-processing is better:**
- LLM outputs most natural structure
- Easier to update rules
- Can handle multiple LLM versions
- Centralized canonicalization

---

## Q3: Phone vs Cellphone vs Mobile - Canonicalization?

**Test Running Now:** `test_canonicalization.py`

Testing these queries:
- "looking for a **phone** under 30k"
- "need a **mobile** under 30k"
- "want to buy a **cellphone** under 30k"
- "searching for a **smartphone** under 30k"

**Expected Results:**
- âœ… API will canonicalize to **ONE** consistent type (probably "smartphone")
- âš ï¸ Might have variations â†’ post-processing with `/data/synonyms.json` ensures 100% consistency

---

## Q4: Polysemy Handling?

**Test Running Now:** Testing "language" in different contexts

### Test Cases:

**Context 1: Programming Language**
```
Query: "need a developer who knows Python language"
Expected: items[].categorical.language = "python"  (tech skill)
```

**Context 2: Speaking Language**
```
Query: "need a plumber who speaks Kannada language"
Expected: other_party_preferences.identity[{type: 'language', value: 'kannada'}]
```

**How API Resolves:**
- Semantic understanding from context
- "developer + Python" â†’ programming skill
- "plumber + Kannada" â†’ spoken language
- Uses axis-based structure for people attributes

---

## Q5: Edge Cases?

**Test Running Now:** Testing:

1. **Currency Detection**
   - "under 50k" â†’ Should detect INR from context
   - "under $500" â†’ Should detect USD
   - "under â‚¹50000" â†’ Should detect INR symbol
   - "under 5 lakh rupees" â†’ Should detect INR + normalize (500000)

2. **Constraint Detection**
   - "16GB RAM" â†’ exact (range with min=max)
   - "at least 16GB" â†’ min constraint
   - "under 80k" â†’ max constraint
   - "between 50k-80k" â†’ range constraint
   - "around 60k" â†’ ??? (test will show)

3. **Implication Rules**
   - "single owner car" â†’ condition:"used" + ownership:"single"
   - "sealed iPhone" â†’ condition:"new" + packaging:"sealed"

---

## ğŸ“Š Test Status

**Currently Running:**
```bash
# 30+ queries testing:
âœ… Canonicalization (phone/mobile/cellphone)
âœ… Polysemy (language, size, experience)
âœ… Currency detection
âœ… Constraint detection
âœ… Implication rules
```

**Results will show:**
- What API handles natively âœ…
- What needs post-processing ğŸ”§
- Accuracy on edge cases ğŸ“Š

**ETA:** ~5 minutes (complex queries take longer)

---

## ğŸ’¡ Key Insights (Preview)

Based on initial test (query 1):

### **What Works:**
- âœ… Semantic understanding (90%+ accurate)
- âœ… Intent/subintent classification (100%)
- âœ… Basic canonicalization (iPhone â†’ smartphone)
- âœ… Constraint detection (at least, under)
- âœ… Attribute extraction (brand, model, condition)

### **What Needs Post-Processing:**
- ğŸ”§ Domain case (technology & electronics â†’ Technology & Electronics)
- ğŸ”§ Currency unit (local â†’ INR/USD)
- ğŸ”§ 100% consistent canonicalization (handle all synonyms)
- ğŸ”§ Schema validation (all 14 fields present)
- ğŸ”§ Unit normalization (month â†’ months)

---

## ğŸ¯ Pipeline Recommendation

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Extraction         â”‚  â† GPT-4o API (for demo)
â”‚ (Semantic understanding)â”‚  â† Fine-tuned Mistral (production)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Post-Processing Layer  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Schema Validation   â”‚  â† Ensure 14 fields
â”‚ 2. Canonicalizer       â”‚  â† /data/synonyms.json
â”‚ 3. Domain Normalizer   â”‚  â† /data/taxonomy.json
â”‚ 4. Currency Detector   â”‚  â† /pos/data/currencies.json
â”‚ 5. Constraint Detector â”‚  â† /pos/data/linguistic_cues.json
â”‚ 6. Implication Rules   â”‚  â† Custom logic
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Canonicalized Output (100% deterministic)
    â†“
Matching Engine
```

**Why this approach:**
- LLM does semantic heavy lifting (90%+ accuracy)
- Post-processing ensures 100% consistency
- Easy to update rules without retraining
- Works with any LLM (GPT, Mistral, Gemini)

---

## ğŸ“ Files to Check

1. **SCHEMA_EXPLANATION.md** - Detailed schema format
2. **test_canonicalization.py** - Comprehensive tests (running)
3. **canonicalization_test_results.json** - Results (generating)
4. **/data/synonyms.json** - Canonicalization mappings
5. **/pos/data/linguistic_cues.json** - Constraint patterns

---

**Next:** Wait for test results (5 min), then analyze patterns and build post-processor.
